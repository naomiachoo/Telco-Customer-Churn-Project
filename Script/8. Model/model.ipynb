{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Modelling"
      ],
      "metadata": {
        "id": "1LeFVXfjdi5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Splitting data train & data test"
      ],
      "metadata": {
        "id": "mdcUTAR-dzDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select independent variables\n",
        "X = telco_data_transformed.drop(columns='Churn')\n",
        "\n",
        "# select dependent variables\n",
        "y = telco_data_transformed.loc[:, 'Churn']\n",
        "\n",
        "# prove that the variables were selected correctly\n",
        "print(X.columns)\n",
        "\n",
        "# prove that the variables were selected correctly\n",
        "print(y.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYC1pT4md3Yk",
        "outputId": "8bb445e8-cee3-4d67-a566-ea0a19393793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['gender', 'MonthlyCharges', 'TotalCharges',\n",
            "       'PaymentMethod_Bank transfer', 'PaymentMethod_Credit card',\n",
            "       'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check'],\n",
            "      dtype='object')\n",
            "Churn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform train test split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40) #fill the code"
      ],
      "metadata": {
        "id": "gayWbdbueIAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_metrics(model):\n",
        "  \"\"\"\n",
        "  Evaluation metrics for classification ML project\n",
        "  \"\"\"\n",
        "  y_predict_train = model.predict(X_train)\n",
        "  y_predict_test = model.predict(X_test)\n",
        "\n",
        "  training_acc = accuracy_score(y_train, y_predict_train) \n",
        "  testing_acc = accuracy_score(y_test, y_predict_test)\n",
        "\n",
        "  print(\"Training Accuracy: {}\".format(training_acc))\n",
        "  print(\"Testing Accuracy: {}\".format(testing_acc))\n",
        "\n",
        "  print(classification_report(y_test, y_predict_test))"
      ],
      "metadata": {
        "id": "WIdy3NaSOvSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics using ROC curve [Optional]\n",
        "def roc_curve_plot(y_test, y_preds):\n",
        "    '''\n",
        "    INPUT:\n",
        "    stuff \n",
        "    OUTPUT:\n",
        "    auc - returns auc as a float\n",
        "    prints the roc curve\n",
        "    '''\n",
        "    \n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(len(y_test)):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test, y_preds[:, 1])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_preds[:, 1].ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "    \n",
        "    plt.plot(fpr[2], tpr[2], color='darkorange',\n",
        "             lw=2, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.show()\n",
        "    \n",
        "    return roc_auc_score(y_test, np.round(y_preds[:, 1]))"
      ],
      "metadata": {
        "id": "fGu3UwefcQZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression"
      ],
      "metadata": {
        "id": "k1toQQ3fg6wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "lr = LogisticRegression() \n",
        "lr.fit(X_train, y_train) ## fill the code\n",
        "\n",
        "evaluation_metrics(lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYNrSwXuevao",
        "outputId": "fc454352-4c7c-4f5d-ec9b-0582064f9951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.7834666666666666\n",
            "Testing Accuracy: 0.7867803837953091\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86      1050\n",
            "           1       0.61      0.45      0.51       357\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.72      0.67      0.69      1407\n",
            "weighted avg       0.77      0.79      0.77      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree"
      ],
      "metadata": {
        "id": "3gKMCypchGuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train) ## fill the code\n",
        "\n",
        "evaluation_metrics(dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNvygGLlhEWd",
        "outputId": "68e36c82-2d35-4b08-a2a2-a38fc65580ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9950222222222223\n",
            "Testing Accuracy: 0.7235252309879175\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81      1050\n",
            "           1       0.46      0.49      0.48       357\n",
            "\n",
            "    accuracy                           0.72      1407\n",
            "   macro avg       0.64      0.65      0.64      1407\n",
            "weighted avg       0.73      0.72      0.73      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradient Boosting"
      ],
      "metadata": {
        "id": "9R-e4vcIhVgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train) ## fill the code\n",
        "\n",
        "evaluation_metrics(gb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2JZiau_hYUI",
        "outputId": "0adc60b7-ba3e-4d3a-90bb-75b39103bbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.8151111111111111\n",
            "Testing Accuracy: 0.7803837953091685\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86      1050\n",
            "           1       0.58      0.50      0.54       357\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.71      0.69      0.70      1407\n",
            "weighted avg       0.77      0.78      0.78      1407\n",
            "\n"
          ]
        }
      ]
    }
  ]
}